# Korean-News-RAPTOR

빅카인즈 주간이슈 뉴스 데이터를 활용한 RAPTOR와 RAG 기반 뉴스 응답 시스템 비교

[BIGKinds 주간이슈](https://www.bigkinds.or.kr/v2/news/weekendNews.do)

## 주간 이슈 뉴스 데이터 수집 기간

**2024-08-26 ~ 2024-08-30**

## 주간 이슈 뉴스 데이터 수집 방법

![image](https://github.com/user-attachments/assets/2c9e809d-7b83-4cb3-9fc5-98e8034241c4)


1. 날짜별로 주간 이슈에 있는 뉴스 데이터를 **빅 카인즈의 뉴스검색.분석에서 엑셀로 데이터 다운로드**

2. 각 엑셀에 있는 **토픽별 뉴스 데이터를 10개씩 수집** (날짜별로 토픽 10개 * 뉴스 10개씩 = 날짜별 100개 => 주간 총합 500개)

3.  5일 동안 수집한 데이터를 **RAG와 RAPTOR를 통해 Vector Store에 저장**

## 연구 소개

ChatGPT와 같은 대형 언어 모델(LLM)의 등장은 다양한 분야에서 자연어 처리 기술의 혁신적인 발전을 이루었지만, 여전히 사전에 학습되지 않은 정보나 특정 질문에 있어서 올바른 대답을 하지 못하는 환각 현상을 보이며, 정확한 답변을 하는데 한계가 있습니다. 예를 들어 공개되지 않은 사내 문서나 특정 데이터에 대한 질문이나, 웹 검색 기반의 경우, 답변에 대한 정보의 신뢰도의 문제 등이 있을 수 있습니다.

이러한 한계를 극복하기 위해 검색-증강 생성(Retrieval-Augmented Generation, RAG) 방법이 등장하였으며, 외부 지식을 활용해 검색 기반의 답변을 생성함으로써, 기존 LLM의 단점을 보완할 수 있습니다. RAG는 외부 지식 저장소를 활용하여, 사용자의 질문과 관련된 정보를 검색한 후, 검색된 데이터를 기반으로 LLM에게 질문을 하여 신뢰성 있고 정확한 답변을 생성하는 방식입니다.

본 연구에서는 빅카인즈의 주간 이슈 뉴스 데이터를 활용하여 RAG 시스템을 구축하고, 이를 통해 사용자의 기사 관련 질문에 대해 검색 기반의 답변을 생성했을 때와 그렇지 않을 때 답변에 대한 차이를 연구합니다. 이를 통해 RAG 시스템이 단순한 LLM 기반 답변과 비교하여 더 신뢰성 있고, 관련성이 높은 답변을 생성하는지에 대한 차이를 분석하고자 합니다.

한편, RAG 시스템을 통해 사용자의 질문에 답변을 생성할 경우, 사용자의 질문이 전반적인 맥락을 이해하거나, 전체적인 내용을 요약한 답변이 필요한 추상적인 질문이라면 적절한 답변을 생성하는데 있어 한계를 보일 수 있습니다. RAG는 질문에 대해 짧고 연속적인 텍스트 청크를 검색하여 답변을 생성하는 방식이기 때문입니다. 예를 들어, "오늘의 주요 뉴스가 무엇인가?" 또는 "특정 주제에 대한 전체적인 요약을 제공해줘"와 같은 구체적이지 않고 추상적인 질문에 대해서는, 전체적인 맥락을 종합한 답변을 생성하는 능력은 제한적일 수 있습니다.

이러한 한계를 극복하기 위해 RAPTOR 시스템이 등장하였습니다. RAPTOR는 RAG와는 달리, 텍스트 청크를 재귀적으로 임베딩하고 클러스터링한 후 요약하는 방식을 통해 전체적인 내용을 포괄하고 요약된 답변을 제공할 수 있습니다.

본 연구에서는 RAG와 RAPTOR 시스템을 비교하여, 빅카인즈의 주간 이슈 뉴스 데이터를 기반으로 사용자의 구체적인 질문뿐만 아니라, 추상적인 질문에 대해서도 RAG와 RAPTOR를 활용했을 때, 사용자의 질문에 대해 어떤 방식이 더 신뢰성 있고 적합한 답변을 제공하는지 평가하고자 합니다.

## 목적 및 필요성

본 연구의 목적은 검색-증강 생성(RAG) 시스템과 RAPTOR 시스템을 비교하여, 두 기법이 사용자의 질문에 대해 생성하는 검색 기반 답변을 평가하는 데 있습니다. 특히, 빅카인즈(BigKinds)의 주간 이슈 뉴스 데이터를 활용하여 구체적인 기사에 대한 질문뿐만 아니라 추상적인 질문에도 두 시스템이 어떻게 대응하는지를 실험적으로 분석합니다. RAG는 기존에 학습되지 않은 정보에 대한 질문에 대해 외부 지식을 활용해 답변을 생성할 수 있다는 강점이 있지만, 짧고 연속된 텍스트 청크를 기반으로 검색하므로 복잡한 질문이나 광범위한 주제에 대해서는 한계를 보일 수 있습니다. 반면 RAPTOR는 텍스트를 재귀적으로 요약하고 클러스터링하여, 질문에 대해 더 포괄적이고 정확한 답변을 제공할 수 있도록 설계된 기법입니다.

LLM의 자연어 처리 능력은 다양한 분야에서 큰 역할을 하고 있지만, 최신 정보나 사전 학습 데이터에 포함되지 않은 질문에 대한 대응에는 제한적입니다. 또한, 웹 검색 기반으로 답변을 생성시 검색 과정에서 해당 정보의 신뢰성이나 중요도가 보장되지 않을 수 있습니다.  빅카인즈와 같은 대규모 뉴스 데이터베이스를 활용하면, 실시간 정보를 기반으로 한 검색-증강 생성 시스템이 구축되어 이러한 문제를 해결할 수 있습니다. RAG와 RAPTOR의 비교를 통해 사용자의 구체적인 질문뿐만 아니라, 추상적인 주제나 광범위한 이슈에 대해서도 두 시스템이 어떻게 반응하는지를 분석함으로써, 더욱 신뢰성 있는 LLM 응용 프로그램의 개발 가능성을 확인할 수 있습니다.

연구의 필요성은 크게 두 가지로 나눌 수 있습니다. 첫째, 기존 LLM의 한계를 보완하는 방법으로서 RAG와 같은 검색 기반 기법의 중요성이 증가하고 있습니다. 대규모 언어 모델은 사전 학습된 데이터에 의존하는 특성상, 최신 정보나 새로운 질문에 대한 환각 현상이 발생할 수 있습니다. 이를 보완하기 위한 기법으로 외부 지식 기반을 활용하는 RAG가 도입되었으나, 추상적인 질문에 대한 한계가 여전히 존재합니다. 둘째, RAPTOR는 이러한 한계를 극복하기 위해 재귀적인 요약 및 클러스터링 기법을 사용하여, 더 넓은 범위의 정보를 바탕으로 적절한 답변을 제공할 수 있습니다. 따라서, 본 연구는 두 시스템의 성능을 비교하여 각 기법의 장단점을 분석하고, 실제 응용 가능성을 평가하는 데 그 필요성이 있습니다.

본 연구 결과는 LLM을 활용한 검색 기반 시스템의 효율성을 높이는 데 기여할 수 있으며, 다양한 질문 유형에 대해 더 나은 답변을 제공하는 시스템을 개발하는 데 중요한 자료로 활용될 수 있을 것입니다.