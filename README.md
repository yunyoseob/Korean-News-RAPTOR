# Korean-News-RAPTOR

빅카인즈 주간이슈 뉴스 데이터를 활용한 RAPTOR와 RAG 기반 뉴스 응답 시스템 비교

[BIGKinds 주간이슈](https://www.bigkinds.or.kr/v2/news/weekendNews.do)

## 연구 소개

ChatGPT와 같은 대형 언어 모델(LLM)의 등장은 다양한 분야에서 자연어 처리 기술의 혁신적인 발전을 이루었지만, 여전히 사전에 학습되지 않은 정보나 특정 질문에 있어서 올바른 대답을 하지 못하는 환각 현상을 보이며, 정확한 답변을 하는데 한계가 있습니다. 예를 들어 공개되지 않은 사내 문서나 특정 데이터에 대한 질문이나, 웹 검색 기반의 경우, 답변에 대한 정보의 신뢰도의 문제 등이 있을 수 있습니다.

이러한 한계를 극복하기 위해 검색-증강 생성(Retrieval-Augmented Generation, RAG) 방법이 등장하였으며, 외부 지식을 활용해 검색 기반의 답변을 생성함으로써, 기존 LLM의 단점을 보완할 수 있습니다. RAG는 외부 지식 저장소를 활용하여, 사용자의 질문과 관련된 정보를 검색한 후, 검색된 데이터를 기반으로 LLM에게 질문을 하여 신뢰성 있고 정확한 답변을 생성하는 방식입니다.

본 연구에서는 빅카인즈의 주간 이슈 뉴스 데이터를 활용하여 RAG 시스템을 구축하고, 이를 통해 사용자의 기사 관련 질문에 대해 검색 기반의 답변을 생성했을 때와 그렇지 않을 때 답변에 대한 차이를 연구합니다. 이를 통해 RAG 시스템이 단순한 LLM 기반 답변과 비교하여 더 신뢰성 있고, 관련성이 높은 답변을 생성하는지에 대한 차이를 분석하고자 합니다.

한편, RAG 시스템을 통해 사용자의 질문에 답변을 생성할 경우, 사용자의 질문이 전반적인 맥락을 이해하거나, 전체적인 내용을 요약한 답변이 필요한 추상적인 질문이라면 적절한 답변을 생성하는데 있어 한계를 보일 수 있습니다. RAG는 질문에 대해 짧고 연속적인 텍스트 청크를 검색하여 답변을 생성하는 방식이기 때문입니다. 예를 들어, "오늘의 주요 뉴스가 무엇인가?" 또는 "특정 주제에 대한 전체적인 요약을 제공해줘"와 같은 구체적이지 않고 추상적인 질문에 대해서는, 전체적인 맥락을 종합한 답변을 생성하는 능력은 제한적일 수 있습니다.

이러한 한계를 극복하기 위해 RAPTOR 시스템이 등장하였습니다. RAPTOR는 RAG와는 달리, 텍스트 청크를 재귀적으로 임베딩하고 클러스터링한 후 요약하는 방식을 통해 전체적인 내용을 포괄하고 요약된 답변을 제공할 수 있습니다.

본 연구에서는 RAG와 RAPTOR 시스템을 비교하여, 빅카인즈의 주간 이슈 뉴스 데이터를 기반으로 사용자의 구체적인 질문뿐만 아니라, 추상적인 질문에 대해서도 RAG와 RAPTOR를 활용했을 때, 사용자의 질문에 대해 어떤 방식이 더 신뢰성 있고 적합한 답변을 제공하는지 평가하고자 합니다.

## 목적 및 필요성

본 연구의 목적은 검색-증강 생성(RAG) 시스템과 RAPTOR 시스템을 비교하여, 두 기법이 사용자의 질문에 대해 생성하는 검색 기반 답변을 평가하는 데 있습니다. 특히, 빅카인즈(BigKinds)의 주간 이슈 뉴스 데이터를 활용하여 구체적인 기사에 대한 질문뿐만 아니라 추상적인 질문에도 두 시스템이 어떻게 대응하는지를 실험적으로 분석합니다. RAG는 기존에 학습되지 않은 정보에 대한 질문에 대해 외부 지식을 활용해 답변을 생성할 수 있다는 강점이 있지만, 짧고 연속된 텍스트 청크를 기반으로 검색하므로 복잡한 질문이나 광범위한 주제에 대해서는 한계를 보일 수 있습니다. 반면 RAPTOR는 텍스트를 재귀적으로 요약하고 클러스터링하여, 질문에 대해 더 포괄적이고 정확한 답변을 제공할 수 있도록 설계된 기법입니다.

LLM의 자연어 처리 능력은 다양한 분야에서 큰 역할을 하고 있지만, 최신 정보나 사전 학습 데이터에 포함되지 않은 질문에 대한 대응에는 제한적입니다. 또한, 웹 검색 기반으로 답변을 생성시 검색 과정에서 해당 정보의 신뢰성이나 중요도가 보장되지 않을 수 있습니다.  빅카인즈와 같은 대규모 뉴스 데이터베이스를 활용하면, 실시간 정보를 기반으로 한 검색-증강 생성 시스템이 구축되어 이러한 문제를 해결할 수 있습니다. RAG와 RAPTOR의 비교를 통해 사용자의 구체적인 질문뿐만 아니라, 추상적인 주제나 광범위한 이슈에 대해서도 두 시스템이 어떻게 반응하는지를 분석함으로써, 더욱 신뢰성 있는 LLM 응용 프로그램의 개발 가능성을 확인할 수 있습니다.

연구의 필요성은 크게 두 가지로 나눌 수 있습니다. 첫째, 기존 LLM의 한계를 보완하는 방법으로서 RAG와 같은 검색 기반 기법의 중요성이 증가하고 있습니다. 대규모 언어 모델은 사전 학습된 데이터에 의존하는 특성상, 최신 정보나 새로운 질문에 대한 환각 현상이 발생할 수 있습니다. 이를 보완하기 위한 기법으로 외부 지식 기반을 활용하는 RAG가 도입되었으나, 추상적인 질문에 대한 한계가 여전히 존재합니다. 둘째, RAPTOR는 이러한 한계를 극복하기 위해 재귀적인 요약 및 클러스터링 기법을 사용하여, 더 넓은 범위의 정보를 바탕으로 적절한 답변을 제공할 수 있습니다. 따라서, 본 연구는 두 시스템의 성능을 비교하여 각 기법의 장단점을 분석하고, 실제 응용 가능성을 평가하는 데 그 필요성이 있습니다.

본 연구 결과는 LLM을 활용한 검색 기반 시스템의 효율성을 높이는 데 기여할 수 있으며, 다양한 질문 유형에 대해 더 나은 답변을 제공하는 시스템을 개발하는 데 중요한 자료로 활용될 수 있을 것입니다.

## 주간 이슈 뉴스 데이터 수집 기간

**2024-08-26 ~ 2024-08-30**

## 주간 이슈 뉴스 데이터 수집 방법

![image](https://github.com/user-attachments/assets/2c9e809d-7b83-4cb3-9fc5-98e8034241c4)


1. 날짜별로 주간 이슈에 있는 뉴스 데이터를 **빅 카인즈의 뉴스검색.분석에서 엑셀로 데이터 다운로드**

2. 각 엑셀에 있는 **토픽별 뉴스 데이터를 10개씩 수집** (날짜별로 토픽 10개 * 뉴스 10개씩 = 날짜별 100개 => 주간 총합 500개)

3.  5일 동안 수집한 데이터를 **RAG와 RAPTOR를 통해 Vector Store에 저장**

## 연구 

1. 빅카인즈의 주간 이슈 데이터 활용: 빅카인즈는 최근 5일간의 주간 이슈를 공개하며, 각 일자별로 10개의 토픽을 제공한다.

2. 데이터 접근성: 각 토픽을 클릭하면 관련된 기사 데이터를 다운로드할 수 있으며, 다운로드된 데이터에는 각 뉴스의 URL 정보가 포함되어 있다.

3. 연구 목표: 이 연구는 주간 이슈에 포함된 토픽에 대해 사용자의 질문에 LLM을 활용하여 답변하는 서비스의 개선을 목표로 한다.

4. RAG의 활용: RAG를 도입하여 환각 현상을 줄이고, 원본 뉴스 데이터를 기반으로 보다 정확한 답변을 제공하고자 한다.

5. RAG의 한계: RAG는 원본 데이터를 벡터 데이터베이스에 임베딩하는 방식을 채택하고 있으나, 전체적인 내용에 대한 추상화된 질문에는 답변하기 어려울 수 있다.

6. 사용자의 요구: 사용자는 각 토픽에 대한 구체적인 내용뿐만 아니라 전체적인 요약 내용에도 관심이 있을 수 있다. RAG를 통한 답변이 이를 충족시킬 수 있을지 의문이다.

7. RAPTOR의 도입 고려: RAPTOR는 긴 문서를 계층적으로 요약하여, 원본과 요약본 모두를 벡터 데이터베이스에 저장하는 방식으로, 추상적 질문에도 요약 기반의 대답이 가능하도록 한다.

8. RAPTOR의 장점 활용: RAPTOR를 도입하면, 하나의 토픽에 대한 사용자의 구체적 및 추상적 질문 모두에 대해 더 효과적인 답변을 제공할 수 있을 것으로 기대된다.

9. RAPTOR의 효과성 검토: 주제가 신문 기사를 기반으로 하고 있으며, 유사한 내용을 다루는 짧은 기사가 많기 때문에 RAPTOR의 도입이 실제로 효과적일지에 대해 신중한 검토가 필요하다.

10. 연구의 범위 및 목표: 이 논문은 빅데이터의 주간 이슈를 기반으로 각 주제에 대해 RAG와 RAPTOR를 구축했을 때의 성능을 비교하여, 사용자의 구체적 및 추상적 질문에 대한 답변 능력을 평가한다.

## To Do

1. Web URL을 기반으로 글자들을 불러올 때, 어떤 Loader를 사용할 것인가?

[langchain: URL](https://python.langchain.com/v0.2/docs/integrations/document_loaders/url/)

[llamaindex: Web Page Reader](https://docs.llamaindex.ai/en/stable/examples/data_connectors/WebPageDemo/)

2. Web URL에서 글자를 추출하였을 때, 기사 이외의 필요없는 텍스트 내용에 대한 전처리는 어떻게 처리할 것인가?

3. **RAG**에 있어서, Chunk Size와 Overlap은 어떻게 할 것 인가?

[Evaluating the Ideal Chunk Size for a RAG System using LlamaIndex](https://www.llamaindex.ai/blog/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5)

4. **RAPTOR**의 경우, 트리 구축 방식을 어떤 것을 사용할 것 인가?

**Tree Traversal Retrieval** vs **Collapsed Tree Retrieval**

5. RAPTOR의 경우 트리 레벨 설정에 있어서 leaf node level을 어떻게 할 것인가?

6. RAPTOR의 경우, Chunk Size와 Overlap은 어떻게 할 것 인가?

7. Splitter는 Recursive Splitter를 사용할 것 인지?

8. RAG의 경우, 각 기사별로 URL을 읽어서 텍스트를 추출 후, 텍스트를 잘라서 벡터 데이터 베이스에 저장 vs RAPTOR의 경우 토픽별로 URL을 읽어서 텍스트를 추출 후, 요약과 함께 벡터 데이터 베이스에 저장으로 할 경우, 둘의 Chunk Size와 Overlap이 같은 상태로 실험하는 것이 유의미한가? 다르게 한 상태로 실험하는 것이 유의미한가?

9. "구체적인 질문"과 "추상적인 질문"은 어떻게 나누어서 실험 할 것인지?

10. 답변을 더 잘했다는 근거와 비교는 어떻게 할 것인지?
